# Lightweight Configuration for DFINE Segmentation
# Optimized for speed and low memory usage - ideal for edge devices and gun AI chips

# Inherit from base configuration
base: "configs/base.yaml"

# Model Tier
tier: "lightweight"

# Model-specific Configuration
model:
  segmentation_head:
    type: "lightweight"
    feature_dim: 128  # Reduced from 256
    dropout_rate: 0.05  # Reduced from 0.1
    
    # Lightweight FPN settings
    fpn:
      use_depthwise_separable: true
      reduced_channels: true
      
    # Ultra-lightweight ASPP settings  
    aspp:
      branches: 3  # Reduced from 4
      use_depthwise_separable: true
      enable_global_pool: true
      
    # Minimal decoder settings
    decoder:
      stages: 1  # Minimal processing
      enable_batch_norm: true

# Training Configuration Overrides
training:
  batch_size: 12  # Can use larger batch due to smaller model
  epochs: 60  # Fewer epochs due to simpler model
  learning_rate: 7e-4  # Slightly higher LR
  
  # Lightweight tier specific settings
  multi_scale_training: false  # Disabled for speed
  augmentation_strength: "light"
  
  # Simplified unfreezing strategy
  unfreeze_epoch: 25
  backbone_lr_factor: 0.1

# Loss Configuration for Lightweight Tier
loss:
  type: "lightweight"
  focal_alpha: 0.25
  focal_gamma: 2.0
  dice_weight: 0.3  # Reduced complexity
  ce_weight: 0.1
  # No boundary loss for speed

# Performance Targets
targets:
  accuracy:
    miou: 0.60  # Lower than standard but still good
    pixel_accuracy: 0.80
  
  speed:
    min_fps: 60  # High FPS target
    max_latency_ms: 16  # Very low latency
  
  memory:
    max_gpu_mb: 2000  # Very low memory usage
    max_model_mb: 50   # Small model size

# TensorRT Configuration for Lightweight Tier
tensorrt:
  fp16: true
  int8: true
  workspace_gb: 2  # Reduced workspace
  
  # Lightweight tier optimization
  optimization_level: 5  # Maximum optimization
  enable_dla: true  # Enable DLA for edge devices
  
  # Smaller input size for speed
  input_shape: [1, 3, 512, 512]  # Reduced from 640x640
  
  calibration:
    mode: "pascal"  # Pascal-only for consistency
    max_images: 300  # Fewer calibration images

# Output Configuration
output:
  base_dir: "outputs/lightweight"
  
# Logging Configuration
logging:
  wandb:
    project: "dfine-lightweight-segmentation"
    tags: ["lightweight", "edge", "fast"]

# Platform-specific optimizations
platform:
  edge_devices:
    jetson_nano: true
    jetson_xavier: true
    raspberry_pi: false  # Too resource constrained
  
  mobile:
    android: true
    ios: true
  
  embedded:
    gun_ai_chip: true
    custom_asic: true

# Comments for clarity
comments: |
  Lightweight tier configuration provides:
  - Maximum speed and efficiency
  - Minimal memory usage
  - Suitable for edge devices and AI chips in guns
  - Target: ~60% mIoU at 60+ FPS
  - Ultra-low latency: <16ms
  - Model size: <50MB
  - GPU memory: <2GB
  - Uses depthwise separable convolutions
  - Optimized for embedded deployment